# ğŸ¤– Case 2: Document-Based Question Answering

## ğŸ“ Scenario
I asked specific questions about the uploaded article **â€œEnhancing Customer Retention in the Telecom Industry with Machine Learning...â€** to simulate writing a critical review or preparing for a class discussion.

---

## ğŸš€ Features Tested

### âœ… Source-Grounded Q&A
NotebookLM provided accurate, document-based answers:
- **Q:** â€œWhat technique does the paper propose?â€  
  **A:** Ratio-Based Data Balancing  
- **Q:** â€œWhich model gave the highest performance?â€  
  **A:** XGBoost with a 75:25 train-test split  
- **Q:** â€œWhat dataset was used?â€  
  **A:** Kaggle Telecom Customer Dataset with 20 features

### âœ… In-Context Citations
Each response included a â€œView sourceâ€ link pointing directly to the relevant section of the article.

---

## ğŸ§  Reflection
The Q&A feature significantly reduced the time needed to locate key information. It was particularly effective for quickly answering assignment-style questions. However, it was less accurate when handling multi-part or open-ended questions that required deeper reasoning.

